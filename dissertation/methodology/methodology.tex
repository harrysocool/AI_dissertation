%!TEX root = ../thesis.tex

\chapter{Methodology}
This chapter will be explaining the method used in this project in order to detect the ear under a 2-Dimensional image. 
Firstly, three object(region) proposal methods will be introduced in order to produces many category-independent and size-unfixed regions per image.
Then the fast R-CNN algorithm for feature extraction and classification of all the regions to determine which one is the actual ear we want.
If there are two many regions correctly classified as ear, it will perform a bounding box regression to precisely localize the box.
Finally, the SOTON ear database is introduced.
%====================================================
%
%====================================================
\section{Object Proposal Methods}
In order to locate the object (in this case the ear), classic approaches over the past two decades have been scanning the whole image by sliding a window which is computational intensive and consequently consuming a lot of times \cite{Girshick:2014vu}. 
Therefore, recently this object proposal approach has become the state-of-art method for object detection in computer vision. 
It dramatically reducing the amount of candidate bounding boxes from tens to hundreds of thousands of locations per image into hundreds of it. 
Moreover, it is generalized for all object categories, unlike the classic method which is necessarily difficult to design and choose features for every object category. 
%====================================================
%
%====================================================
\subsection{Selective Search}
One of the popular approach is Selective Search proposed by J.R.R. Uijlings et al. in 2013\cite{Uijlings:2013eg}. 
It has been widely used for object detection method in 2012, and the detection method based on it produced a very good result in the PASCAL VOC challenge.
It is common in the last decades that to use a sliding window for performing exhaustive search to generates region proposals.
Although the search space was reduced by using some method such as regular grid, fixed scales, and fixed aspect ratios. 
In most cases, it still remain huge number of locations to visit.
Need not to mention that many of the regions is not supportive at all, because there are no rules for selection of those regions.
Therefore, people start to design an algorithm that performs data-driven analysis on an image which can produce generalised region for only object contains in the image.
The main procedure of it can be described as below: 
\begin{enumerate}
  \itemsep=-0.5em
  \indentitem\item Produce regions from an image based on the "Efficient GraphBased Image Segmentation"\cite{Felzenszwalb:2004bx} method.
  \indentitem\item Computing the similarity between each region.
  \indentitem\item Merge the most similar region.
  \indentitem\item Keep doing the last two steps until convergences.
  \indentitem\item Choose a Stochastic scoring method to ranking those regions and the subset of top $k$ region is the result.
\end{enumerate}
It also have two \textbf{diversification strategies}, one for color spaces including RGB, Lab and so on, the other is for the calculating of region similarity involving color, texture and region size. 
As it shown in figure \ref{ss_1}, the step 2\&3 can be seen as producing "multiscale" of the image which allows it to present different size of object proposals.

\fig{ss_1}{Example of Selective Search method on "multiscale"}{0.7}
\improvement{the result of the ear pictures}
%====================================================
%
%====================================================
\subsection{Edge Boxes}
In 2014, an improved approach which based on the edge information of an image has been developed by C. Lawrence Zitnick and Pitor Doll\'ar \cite{Zitnick:2014gi}. It can produce the amount of $10^{3}$ proposals in about 0.25s. The main procedure is described below:
\begin{enumerate}
  \itemsep=-0.5em
  \indentitem\item It uses "Structured Decision Forests \cite{Dollar:2015wy}" method to produce edge informations of the image.
  \indentitem\item Use Non Maximum Suppression(NMS) to obtain a more sparse edge image.
  \indentitem\item Grouping all the edge point into different edge groups as shown in different color in figure \ref{ed_1}.
  \indentitem\item Calculate the affinity between edge groups using author's formula. 
  \indentitem\item Computing object proposal score, higher score will be potential objects.
\end{enumerate}

\fig{ed_1}{Illustration examples for the process of Edge Boxes method}{0.7}
\improvement{result}
%====================================================
%
%====================================================
\subsection{Binarized Normed Gradients (BING)}
This method is the fastest one among all the object proposal method recently \cite{Hosang:2014um}, it can achieve 300fps on a single laptop CPU \cite{Cheng:2014tf}.
\begin{enumerate}
  \itemsep=-0.5em
  \indentitem\item Produce a series of normed gradient from the image in different scales and aspect ratios.
  \indentitem\item Use Non Maximum Suppression(NMS) to obtain 8*8 gradient feature.
  \indentitem\item Binarize those features in order to obtain Binarized Normed Gradient(BING) features.
  \indentitem\item Calculate the value of objectness, use it to rank the object.
\end{enumerate}

Due to the special algorithm which transform the 8*8 BING features into a single int64 and a byte of the last row as shown in figure \ref{BING_2}. It dramatically reduced computation by avoiding 8 for-loops every time, and enable it to perform atomic operation (such as bitwise SHIFT and bitwise OR).

\fig{BING_1}{Object(red) and non-object(green) (a) corresponds to normed gradients(NG) features (c) in proper scales and aspect ratios (b), a single 64D linear model (d) can be learned}{0.6}
\fig{BING_2}{Illustration of variables: a BING feature}{0.6}
\improvement{result}
%====================================================
%
%====================================================
\section{Deep Learning Method}
In recent years, the using of deep convolutional neural networks (also known as deep learning method) has significantly improve the accuracy in image classification and object detection. The biggest advantage of deep learning is that no need to spend time design and decide for the specific hand-crafted features to use, which also means it can become a generalized solution for different tasks. Although the disadvantages are quite clear, it requires large amount of memories, calculation and consequently time-consuming. One of the solution now is to use GPU to calculate which accelerate the computation quite a lot.

The Fast R-CNN method has been chosen for this project as a solution towards the ear detection problem, because the source code in open in public, require less time for training than the previous version (RCNN) and can modify different object proposal methods compare to the latest version (Faster R-CNN).

\subsection{Fast Region-based Convolutional Network (Fast R-CNN)}
Because the ear detection can be seen as a specific object detection task, therefore, the state-of-art method on PASCAL VOC challenge will be very useful. In 2015, Ross Girshick designed this Fast-RCNN algorithm \cite{Girshick:2015vra} based on the improvement of his previous RCNN \cite{Girshick:2014vu} method, and quickly become one of the popular method in the challenge. It reaches 70 mean Average Precision(mAP) under the dataset of PASCAL VOC 2007, and runs 9x faster than R-CNN at training-time and 200x faster at testing-time. 

As it shown in figure \ref{frcnn_1}, this algorithm can be divided into 4 main steps:
\begin{enumerate}
  \itemsep=-0.5em
  \indentitem\item Object proposal boxes and ground truth object box for each image goes into the network.
  \indentitem\item Use convolutional network to extract features from each proposal boxes, involving Region of Interest (ROI) projection method to prevent multiple calculation.
  \indentitem\item Training classifier to decide whether a proposal box belong to one of the classes. 
  \indentitem\item For each set of overlapping proposal boxes, use a regressor to obtain the final precise location.
\end{enumerate}

Therefore, two outputs were presented as in figure \ref{frcnn_1}, one for the probability of which class the corresponding box is, the other for the bounding box location. 
In this case, $ear$ and $\_\_background\_\_$ are the only two classes which actually simplified the training process. 
\fig{frcnn_1}{Fast R-CNN architecture\cite{Girshick:2015vra}}{0.8}

It is also very important to choose which pre-trained Convolutional Neural Network (CNN) shown as the middle part in figure \ref{frcnn_1} to use, different network contains different structures such as how many levels of convolution layers, pooling layers and full connecting layers.
The author of fast-rcnn, Ross Girshick recommended to use his pre-trained (trained under PASCAL VOC dataset) models:  
\begin{itemize}
\itemsep=-0.5em
  \item \textbf{CaffeNet} refer to author as essentially "AlexNet" which is the first CNN invented by Hinton et al. \cite{Krizhevsky:2012wl}. This is a small one compare to others.
  \item \textbf{VGG\_CNN\_M\_1024} which has the same depth as CaffeNet, but the architecture is wider \cite{Chatfield:2014dl}, referred as medium size.
  \item \textbf{VGG16} is a very deep model from Karen Simonyan \cite{Simonyan:2014ws} in 2015. This is the largest model.
\end{itemize}

Due to the limitation of the current GPU hardware we have as described in appendix \change{appendix of laptop} and the amount of training time we are willing to tolerate, the small one "CaffeNet" has been chosen as our network.
However, the full training time of 40,000 iteration (as recommended) on the database of our choice in section 2.2.2 is still up to 6 hours. 
%====================================================
%
%====================================================
\section{Database}
This project uses the ear image database obtained by University of Southampton gait lab \cite{database}.
It covers more than 400 peopleâ€™s profile of gait, face and ear while they walking pass a tunnel. 
Therefore the ear images was collected in an unconstrained way, as subjects walking pasted a camera. 
The illumination while capturing pictures is also not very good as shown in figure \ref{database_1}, moreover, the tunnel has some painted background used for camera calibration which also make it more challenge for ear detection.
But, these are good for training a robust ear detection algorithm.
Another advantage of this database is it also contains the ear location of each image which is convenient for directly use as the ground truth in deep learning network.
\fig{database_1}{Sample images from SOTON ear database}{0.8}

The database contains totally 600*800 sized 548 colour images with 2-4 images per subject, we randomly divided it into 80\% training (437 images) and 20\% testing (111 images). 
The only augment for images while training the network is a horizontally mirror image due to the ear is pair-wised for human beings.

