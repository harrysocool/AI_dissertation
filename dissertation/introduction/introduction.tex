%!TEX root = ../thesis.tex

\chapter{Introduction}

\section{Motivation and Objectives}

Motivation and Objectives here.

\section{Literature Reviews}
\subsection{The Early Work towards Ear Forensics by Iannarelli}
In 1949, Alfred Iannarelli was well-known in American as an ear identification export who providing ear evidence as a strong personal identification in the context of forensic science\cite{State:1999}. He also developed a measurement system in order to representing the ear by numbers, which was used by American law enforcement agencies at that time\cite{Arbab-Zavar:2009}. As shown in Figure \ref{Iannarel_ear}, he aligned the ear into 4 reference lines which divided the image into equally 45\degree\ intervals. The intersection of those lines is located on the tragus and the crus of helix (see section 4.1 for a description of the anatomical parts of the ear)\unsure{Need change the references}, therefore the ear image can be represented based on the edge markers of each reference line.

\fig{Iannarel_ear}{Iannarelliâ€™s manual ear measurement system.}{0.3} 

According to Iannarelli's book, through 38 years of research and application in earology on more than 10,000 ear images, no two ears were found to be identical, not even the two ears from the same person\cite{Arbab-Zavar:2009}.
\unsure{Maybe more conclusion}

Although this system was based on a man-power visual measurement which may be not very accurate, the usage time of the successful application has proved itself to be very useful. It also inspired a lot of researches towards ear recognition using more advanced technology later.

\subsection{Burge and Burgers' method}
In the early time of the 21st Century, Burge and Burger started to use machine vision for ear recognition system. They were the first who managed to use machine model each individual ear with an adjacency graph.

The main step of their method can be shown as figure \ref{burge_ear}. They used the canny edge detection firstly to extract the "ear print", then reconstructed it into a Voronoi diagram which looks like a segmentation of the ear parts. Finally, join the center of each segment to form the "N-graph" which is used to authenticating a person.

\fig{burge_ear}{Burge and Burgers' ear model method.}{0.55}

\subsection{Reduced Hough Transform for Ear Detection}
Hough Transform (HT) is a very classic algorithm in image processing widely used for feature extraction and patten recognition. It is useful to find the imperfect instances of objects in certain shapes which is very suitable for ear detection as the ear is just like a ellipse and remains that way. Hence, in 2007 Arbab-Zavar et al.\cite{ArbabZavar:2007hr} used it to design an algorithm for automatic ear detection. Despite the advantages, HT has certain drawbacks such as high computational requirement and memory usages, therefore they used a reduced Hough Transform to overcome those problems as it was specified for only detect ellipse using the known geometrical properties of it to decompose the parameter space from 5D to 2D.

\fig{arbab_1}{The process of Arbab-Zavar's method \cite{ArbabZavar:2007hr}. (b)Canny edge (c)accumulator of ellipse (d)reduce the horizontal vote}{0.9}

Firstly, a Canny operator is applied to get a smoothed edge detected image, then the reduced HT transform reconstruct it into an accumulator space as it shown in figure \ref{arbab_1} (c). The locations of the peaks will provide the coordination of the best matching ellipse. However, there are some mismatches as well, such as the presence of the spectacles. The way to eliminate most of them is to get rid of the horizontal vote by HT, due to the ear shape is mostly a vertical ellipse in the database. 

The result shows that this algorithm achieves error-free on the XM2VTS derived, 252-image database. But not that good in UND database, given that it include more backgrounds informations. When applying occlusions, despite the HT was known as tolerate to noise and imperfect, the detection accuracy still drops below 80\% after 40\% occlusion percentages and reaches 30\% at 70\% partial occlusion \cite{ArbabZavar:2007hr}. This algorithm can be seen as very successful under the condition of head profile only database, without backgrounds and large hair covers. It is a very good example of how to maximize the usage of classic methods, however the speed of detection needs to be evaluated if the algorithm needs to be improved.

\subsection{Shaped Wavelets for Ear Detection}
Due to the ear image mainly contains a lot of curvilinear structures, Ibrahim et al.\cite{Ibrahim:2010dc} convolve the image with some curved wavelet filters called "banana wavelet" shown as the figure \ref{banana_1} to perform a generalized template matching to detect the location of ear.

\fig{banana_1}{Banana wavelets used in this method\cite{Ibrahim:2010dc} .}{0.55}

The Banana wavelets are a generalization of Gabor wavelets and it can be parameterized by four variables: frequency, curvature, orientation and size. They use 8 filters which prove to be sufficient for ear detection as it shown above in figure \ref{banana_1}. Initially, they do the convolution between image and the banana wavelet which resulting the magnitude of the filter response. Then the local maxima of the magnitude should be the position where ear has similar curvature, size and orientation to the specific corresponding banana wavelets, as it shown below in figure \ref{banana_2}. Finally, some threshold and anti-overlapping algorithms can be applied to make the decision where is the ear. 

\fig{banana_2}{(a) Input image, and (b)-(i) after convolution with 8 banana filters\cite{Ibrahim:2010dc}}{0.65}

The results demonstrate that this is a very promising methods which achieve 100\% detection rate on the XM2VTS database and above 98\% when the Gaussian noise ($\sigma = 100$) is presented. However, when testing on the SOTON database \unsure{database references} with some occlusion, the detection accuracy drop dramatically to 44.7\% with partial head and small occlusion\cite{Ibrahim:2010dc} . 

Although the algorithm treat the ear as the combination of some curved lines and focus on finding those lines, it cannot achieve better detection rate when occlusion occurs. The amount of calculation must be very big due to the several fully convolution of whole image with 8 wavelet filters, but the author did not mention anything about speed. 