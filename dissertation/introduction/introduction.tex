%!TEX root = ../thesis.tex

\chapter{Introduction}
Human ear, as a very promising biometric identifier has drew lots of attentions in biometric communities recently \cite{Ibrahim:2011dq}. It contains sufficient curved structures which will not change radically from age 8-70 years old and are unaffected by cosmetics, unlike face \cite{Burge:2000ek}. Compare to gait, it cannot be easily changed intentionally by the subject when doing a surveillance. Which makes it a perfect and promising biometric for access control, security and video surveillance.

Recently, people trends to focus on using 3D data or combine 2D with 3D data due to it can overcome the illumination and pose variation of ear recognition, although it can get much better result now, special equipment and expensive computation will be needed \cite{Yuan:2012db}. However, this manuscript will concentrate on 2D images, because of the consistency when deploy in surveillance or other planar image scenarios \cite{ArbabZavar:2011cn}.
%====================================================
%
%====================================================
\section{Motivation and Objectives}
The main motivation for ear recognition would be the implementation of an algorithm which can automatically tell the identity of a person via only taking pictures of his ear. Such a system can then be used for security surveillance, collect crime evidences and attendance check. Combined with the state-of-art face recognition system, they can provide more accurate identification rate and be more reliable. 

For an automatic ear recognition system, it contains three main parts: ear detection, feature extraction and identification (classification). Due to the limitation of time in this project, it is better to focus on one part out of all three. Therefore, this project will concentrate on the first part \textbf{ear detection} which has very significant impact to the following procedures. For example, if the ear failed to be registered inside an image, the following steps tend to be meaningless and may cause incorrect detection rate data. 

Therefore, the objective of this project can be listed below:
\vspace{-4mm}
\begin{itemize}
\itemsep=-0.5em
  \item Implement an algorithm which has good detection rate on ear images under some circumstances such as occlusion and noises which often occur in the real world scenario. 
  \item Attempt to use state-of-art deep-learning convolutional neural network method instead of classic hand-craft feature spaces.
  \item Reduce the time for the detection so that it can be used as a live detection.
\end{itemize}
%====================================================
%
%====================================================
\section{Outline}
This manuscript is divided into 4 chapters which mainly covered all the informations required. 
Chapter 1 is the introduction of the whole picture followed by the literature review of classic methods on ear detection applications and the initial use of CNN on object detection.
Chapter 2 introduce all the methods employed in this project, including 3 object proposal methods and the main fast R-CNN algorithm.
The database that this project used is described followed as well.
Chapter 3 shows the result of this method under different restrictions as it usually happened in the real world. 
And the analysis of time usage in different part of the algorithms.
The final chapter will discuss the utility of results in the previous chapter, and make a conclusion of the achievement and contribution of this project.
Appendix will include the platform specification and a brief introduction of the environment set-up.
%====================================================
%
%====================================================
\section{Literature Reviews}
In this section, the previous work in ear detection is presented with descriptive words. It was mainly about the classic methods which focus more on how to design the feature space then scan the whole image to match such features. However, we are implementing a novel method for ear detection which no one has done before, no related paper can be discussed in this section about it.

\subsection{Reduced Hough Transform for Ear Detection}
Hough Transform (HT) is a very classic algorithm in image processing widely used for feature extraction and patten recognition. It is useful to find the imperfect instances of objects in certain shapes which is very suitable for ear detection as the ear is just like a ellipse and remains that way. Hence, in 2007 Arbab-Zavar et al.\cite{ArbabZavar:2007hr} used it to design an algorithm for automatic ear detection. Despite the advantages, HT has certain drawbacks such as high computational requirement and memory usages, therefore they used a reduced Hough Transform to overcome those problems as it was specified for only detect ellipse using the known geometrical properties of it to decompose the parameter space from 5D to 2D.

\fig{arbab_1}{The process of Arbab-Zavar's method \cite{ArbabZavar:2007hr}. (b)Canny edge (c)accumulator of ellipse (d)reduce the horizontal vote}{0.9}

Firstly, a Canny operator is applied to get a smoothed edge detected image, then the reduced HT transform reconstruct it into an accumulator space as it shown in figure \ref{arbab_1} (c). The locations of the peaks will provide the coordination of the best matching ellipse. However, there are some mismatches as well, such as the presence of the spectacles. The way to eliminate most of them is to get rid of the horizontal vote by HT, due to the ear shape is mostly a vertical ellipse in the database. 

The result shows that this algorithm achieves error-free on the XM2VTS derived, 252-image database. But not that good in UND database, given that it include more backgrounds informations. When applying occlusions, despite the HT was known as tolerate to noise and imperfect, the detection accuracy still drops below 80\% after 40\% occlusion percentages and reaches 30\% at 70\% partial occlusion \cite{ArbabZavar:2007hr}. This algorithm can be seen as very successful under the condition of head profile only database, without backgrounds and large hair covers. It is a very good example of how to maximize the usage of classic methods, however the speed of detection needs to be evaluated if the algorithm needs to be improved.
%=========================================================

\subsection{Haar-like Features for Ear Detection} 
The Haar-like feature was a very successful algorithm when applied for human face detection by Viola at 2001\cite{Viola:2001un}. 
Therefore, in 2009 Yuan et al.\cite{Yuan:2009js} designed an algorithm which used Haar-like features for ear detection. 
There are some extended asymmetric Haar-like features shown in figure \ref{Yuan_1} were added, due to the ear structure is very different from face it has more curved outlines.

\figtwoo{Yuan_1}{Haar-like features reflects the local features}{0.7}{Yuan_2}{The procedure of classify ears}{0.9}

They trained several strong classifiers with AdaBoost algorithm and then cascaded them together into a multi-layer classifier \cite{Yuan:2009js}. 
As all the sub-windows of the image pass through each one of the single classifier, false response will immediately reject the corresponding sub-window. 
Only the one went through all classifiers will be marked as an human ear.

The training sample came from their own database USTB which including 11,000 images with half left ear and half right. 
There are also 10,000 negative samples from another face database. 
The result was very impressive with only 0.5\% False Reject Rate and 2.3\% False Acceptance Rate on USTB 220 testing images. 
However this method will be highly related to the quality of training dataset and require good control of over-fitting.

\subsection{SIFT Point Matching for Ear Detection}
Scale-invariant feature transform also known as SIFT is a famous computer vision algorithm for detecting and describing local features in images. It extract the interest point of the object in an image to provide "feature description" of the object, then a chosen distance can be used to decide if two description are the same between two images. Advantages of the SIFT for ear detection is that it is scale-invariant and not sensitive with noise and illumination.

Based on the method written by Brown et al.\cite{Brown:2002is}, they try to created a homography transform between a probe image and a known gallery object image using SIFT matches. If an homography can be created, means that the probe contains the gallery object. In addition, 4 matched SIFT points were used to align if they lies in one plane , due to the unreliability of more points. Although it can provided an accurate result, a RANSAC algorithm was used to select the best match.

The detection result was under the XM2VTS derived, 252-image database shown that it achieved 96\% rank-1 detection accuracy \cite{Bustard:2008ha}. However it requires the predefined galley of object image which needs a manual mask to locate the object.

\subsection{Shaped Wavelets for Ear Detection}
Due to the ear image mainly contains a lot of curvilinear structures, Ibrahim et al.\cite{Ibrahim:2010dc} convolve the image with some curved wavelet filters called "banana wavelet" shown as the figure \ref{banana_1} to perform a generalized template matching to detect the location of ear.

\fig{banana_1}{Banana wavelets used in this method\cite{Ibrahim:2010dc}.}{0.65}

The Banana wavelets are a generalization of Gabor wavelets and it can be parameterized by four variables: frequency, curvature, orientation and size. They use 8 filters which prove to be sufficient for ear detection as it shown above in figure \ref{banana_1}. Initially, they do the convolution between image and the banana wavelet which resulting the magnitude of the filter response. Then the local maxima of the magnitude should be the position where ear has similar curvature, size and orientation to the specific corresponding banana wavelets, as it shown below in figure \ref{banana_2}. Finally, some threshold and anti-overlapping algorithms can be applied to make the decision where is the ear. 

\fig{banana_2}{(a) Input image, and (b)-(i) after convolution with 8 banana filters\cite{Ibrahim:2010dc}}{0.65}

The results demonstrate that this is a very promising methods which achieve 100\% detection rate on the XM2VTS database and above 98\% when the Gaussian noise ($\sigma = 100$) is presented. However, when testing on the SOTON database with some occlusion, the detection accuracy drop dramatically to 44.7\% with partial head and small occlusion\cite{Ibrahim:2010dc}. 

Although the algorithm treat the ear as the combination of some curved lines and focus on finding those lines, it cannot achieve better detection rate when occlusion occurs. The amount of calculation must be very big due to the several fully convolution of whole image with 8 wavelet filters, but the author did not mention anything about speed. 

\subsection{Active Contour for Ear Detection}
In 2011, Kumar et al.\cite{Kumar:2011ci} tried to develop an online application which can use ear biometric as an authentication method. They build a wooden stand for acquiring the image as it shown in figure \ref{kumar_1}, so there are no extra illumination management require, the ear was captured inside a isolated box with utilized camera flash light. Which should make the detection more easy, however can not handle the real scenario image.

\fig{kumar_1}{(a)Imaging setup (b)Sample captured image}{0.65}

First of all, they use Gaussian classifier to detect the skin region, then apply LoG(Laplacian of Gaussian) for edge detection and remove the false edge until only ear edge left. By using the top and bottom pixel of the ear edge, they can manage to rotate the ear with reference to the vertical axis. Finally, a localized region based active contour model is applied to extract the ear part only from the ear-ROI(Region of Interest). The whole process is shown in figure \ref{kumar_2}.

\fig{kumar_2}{(a)Ear Edge by LoG (b)False edge removal (c)ear-ROI (d)Ear-contours}{0.65}

The database they created is 100 users with 7 pictures each. However, the detection rate from the ear-ROI is about 94.2\%, which means the correct ear-contours extract is 660 images, the blurry images and the presence of hair are the ones failed \cite{Kumar:2011ci}. As they only uses the specific controllable database, it is no doubt that this method will failed more when applying in real life images.

\subsection{Deep Convolutional Neural Network}
In 2012, Hinton and his colleges in University of Toronto decided to use deep convolutional neural networks solving the image classification problem \cite{Krizhevsky:2012wl}
They designed a deep network which has 60 million parameters and 650,000 neurons, contains five layers of convolution and some max-pooling layers. 
Three fully-connected layers forwards data into a 1000-way softmax classification result, due to the ImageNet LSVRC-2010 database has 1000 different classes. 

\fig{convnet_2}{Architecture of the Convolutional Neural Network \cite{Krizhevsky:2012wl}}{0.8}

The architecture can be found above in figure \ref{convnet_2} which shows two parallel processes of the network.
It was because that the database has 1.2 million training examples which too big to fit on one GTX 580 GPU with only 3GB memory.
Therefore each GPU takes half of the first layer convolutional kernels which are 48 and performing a concurrent training with data communicating at certain layers.

In order to reduce the chances of over-fitting which can easily happen in this network due to the large amount of parameters, they augment the data by extracting random 224 x 224 patches (and their horizontal reflections) and uses "dropout" techniques which randomly shut down hidden neurons with 0.5 probabilities.
The result they achieved is way better than the previous state-of-art, decreased almost 10\% error rates on ILSVRC-2010 test set.
They noticed that the architecture is important for network performance, even the remove of a single convolutional layer
will degrades result.

\fig{convnet_1}{Historical PASCAL VOC object detection rate}{0.6}

The contribution of this CNN architecture is enormous, lots of following researches aimed on object detection and image classification were based on the modified version of it.
As it shown in figure \ref{convnet_1}, the successful application of CNN quickly pulls up the mean Average Precision (mAP) in PASCAL VOC challenge recently. 
The method that used in this project also take advantages on it.
\subsection{Big Improvement on Object Detection}
The most famous and also the first rank of PASCAL VOC 2012 object detection challenge in 2014 is the algorithm called R-CNN designed by Ross Girshick \cite{Girshick:2014vu}.
It amazingly improved the mAP by 30\% and firstly indicate that a CNN can lead to dramatically higher object detection performance on PASCAL VOC as compared to systems based on simpler HOG-like hand-craft features.

\fig{object_1}{Object detection system overview}{0.9}

Object detection require one more step than image classification, localization.
It can be solved by a sliding-window detector which CNN has been used for at least two decades.
However, Ross solved it by obtains an region generating procedure first and name it as the “recognition using regions” paradigm \cite{Girshick:2014vu}.
First of all, they generates around 2000 category-independent size-unfixed region proposals of the image.
Then use a simple method to wrap those region proposals into fixed size for CNN input.
Finally CNN will output fixed-length feature vector for each proposal, then it can be classified by category-specific linear SVMs.

The second principle contribution of this paper is called "fine-tuning" when your database is scarce due to the size of CNN.
ROSS uses the very big ImageNet Large Scale Visual Recognition Challenge (ILSVRC) dataset as an auxiliary supervised pre-training to initialise weights in CNN.
Then fine-tuning it on a more domain specific smaller dataset which one can normally have. 
Their experiment proves that fine-tuning improves mAP performance by 8 percentage points.

It is a big step towards good performance computer vision object detection which stagnated for years.
By the inspire of this method, we hereby use it to solve the ear detection as a specific object detection method in this project. 